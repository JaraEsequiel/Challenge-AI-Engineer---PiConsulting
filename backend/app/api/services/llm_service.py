class LLMService:
    async def generate_message(self, content: str) -> str:
        # Aquí iría la lógica para generar el mensaje usando un modelo de lenguaje
        return f"Generated message based on: {content}"
